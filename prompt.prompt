---
# File prompt prompt
# Defines prompt object generates prompt language specification
version: zero point seven point zero # Reflects spec target version
description: "A meta prompt object that generates the technical specification for the prompt language itself" # Punctuation removed
author: "AI Collaboration"
tags: ["meta", "specification", "language-design"]
defaultSpecModel: { model_id: "gemini-1.5-pro", temperature: 0.5 }
---

# This prompt file generates prompt language specification text
# It embodies meta programming capabilities language

# Import conceptual interaction layer
# import AI_Interaction
import asyncio # For async main conceptual

class LanguageSpecGeneratorPrompt: # Conceptually BasePrompt

    def __init__(self, target_model_config=None):
        # Initializes generator takes optional model config
        if target_model_config:
            self.targetModel = target_model_config
        elif metadata.defaultSpecModel: # Access metadata
             self.targetModel = metadata.defaultSpecModel
        else:
             raise ValueError("Missing model configuration for spec generation") # Keep error punctuation
        print("[INFO] LanguageSpecGeneratorPrompt initialized") # Punc removed

    def generate_prompt_text(self) -> str:
        # Returns meticulously crafted prompt ask LLM generate spec
        # This internal prompt string IS procedural retains its punctuation numbers etc
        return f"""
        **Objective:** Generate a detailed technical specification document for a dedicated prompt engineering language tentatively named '.prompt'.

        **Target Audience:** Language implementers and advanced users.

        **Core Design Principles:**
          - Object-Oriented Structure (Classes/Objects for prompts/agents)
          - Strong Encapsulation (State + Behavior)
          - First-Class Prompt Artifacts (Versionable, Testable)
          - Native Iteration/Recursion Support
          - Pythonic Syntax Base, Loosely Typed Runtime
          - Markdown-like Readability for Embedded Prompt Text
          - Async Native for I/O (Model Calls)
          - Support for Multimodality (Text, Image, Conceptual Components)
          - Support for Constraints/Reward-based Optimization Directives
          - Support for Agentic Structures (State, Perception, Planning, Action, Tools)
          - Standardized Metadata Block (YAML)
          - Conceptual Standard Library (e.g., JSON, input(), AI_Interaction)

        **Required Features for Specification:** Detail the implementation approach for these features, including Syntax & Grammar (formal preferred), Type System (loose typing details), Object Model (BasePrompt, BaseAgent), Control Flow, Templating, Recursive Constructs, Model Interaction Layer, Metadata Standard, Standard Library, Agent Framework, Multimodal types, Constraint Syntax.

        **Output Deliverable:** A comprehensive technical specification document structured logically (Introduction, Lexical Structure, Type System, Object Model, Control Flow, Specialized Constructs, Model API, Metadata, Standard Lib, Agent Framework, Multimodal/Constraints Syntax, Code Examples, Open Issues).

        **Instructions:** Generate ONLY the specification document text, formatted clearly (e.g., using Markdown). Be thorough and precise.
        """

    async def execute(self) -> str:
        # Generates specification text calling AI model
        prompt_text = self.generate_prompt_text()
        print("[INFO] Generating language specification via LLM call") # Punc removed

        try:
            # Conceptual call abstracted interaction layer
            specification_content = await AI_Interaction.generate_text(
                modelConfig=self.targetModel,
                prompt=prompt_text
            )
            print("[SUCCESS] Specification content generated") # Punc removed
            return specification_content.strip()
        except Exception as e: # Simple error handling example
            print(f"[ERROR] Failed spec generation {e}") # Punc removed
            raise # Propagate error

# --- Script Execution Block ---
async def main():
    print("[SCRIPT START] Generating prompt language specification") # Punc removed
    spec_generator = LanguageSpecGeneratorPrompt()

    try:
        spec_doc = await spec_generator.execute()
        print("\n--- Generated Specification (Conceptual Output) ---") # Punc removed
        # In real usage might save spec_doc file
        # Limiting print output clarity
        print(spec_doc[:1000] + "\n...") # Print first thousand chars concept punctuation removed
        print("-------------------------------------------------") # Structure kept
    except Exception as e:
        print(f"[FATAL] Script failed {e}") # Punc removed

# Run main async function
asyncio.run(main())
