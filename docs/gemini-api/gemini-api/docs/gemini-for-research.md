# Accelerate discovery with Gemini for Research

[Get a Gemini API Key](https://aistudio.google.com/apikey)

Gemini models can be used to advance foundational research across disciplines.
Here are ways that you can explore Gemini for your research:

* **Fine-tuning**: You can fine-tune Gemini models for a variety of modalities to
  advance your research. [Learn more](/gemini-api/docs/model-tuning/tutorial).
* **Analyze and control model outputs**: For further analysis, you can examine a
  response candidate generated by the model using tools like `Logprobs` and
  `CitationMetadata`. You can also configure options for model generation and
  outputs, such as `responseSchema`, `topP`, and `topK`. [Learn more](/api/generate-content).
* **Multimodal inputs**: Gemini can process images, audio, and videos, enabling a
  multitude of exciting research directions. [Learn more](/gemini-api/docs/vision).
* **Long-context capabilities**: Gemini 1.5 Flash comes with a 1-million-token
  context window, and Gemini 1.5 Pro comes with a 2-million-token context window.
  [Learn more](/gemini-api/docs/long-context).
* **Grow with Google**: Quickly access Gemini models through the API and Google AI
  Studio for production use cases. If you're looking for a Google Cloud-based
  platform, Vertex AI can provide additional supporting infrastructure.

To support academic research and drive cutting-edge research, Google provides
access to Gemini API credits for scientists and academic researchers through the
[Gemini Academic Program](/gemini-api/docs/gemini-for-research#gemini-academic-program).

## Get started with Gemini

The Gemini API and Google AI Studio help you start working with Google's latest
models and turn your ideas into applications that scale.

[Python](#python)[JavaScript](#javascript)[REST](#rest)
More

```
from google import genai

client = genai.Client(api_key="YOUR_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="How large is the universe?",
)

print(response.text)

```
```
import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: "YOUR_API_KEY" });

async function main() {
  const response = await ai.models.generateContent({
    model: "gemini-2.0-flash",
    contents: "How large is the universe?",
  });
  console.log(response.text);
}

await main();

```
```
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=YOUR_API_KEY" \
-H 'Content-Type: application/json' \
-X POST \
-d '{
  "contents": [{
    "parts":[{"text": "How large is the universe?"}]
    }]
   }'

```

## Featured academics

![](/static/site-assets/images/diyi-yang.png)

"Our research investigates Gemini as a visual language model (VLM) and its agentic behaviors in diverse environments from robustness and safety perspectives. So far, we have evaluated Gemini's robustness against distractions such as pop-up windows when VLM agents perform computer tasks, and have leveraged Gemini to analyze social interaction, temporal events as well as risk factors based on video input."

![](/static/site-assets/images/lerrel-pinto.png)

"Gemini Pro and Flash, with their long context window, have been helping us in OK-Robot, our open-vocabulary mobile manipulation project. Gemini enables complex natural language queries and commands over the robot's "memory": in this case, previous observations made by the robot over a long operation duration. Mahi Shafiullah and I are also using Gemini to decompose tasks into code that the robot can execute in the real world."

## Gemini Academic Program

Qualified academic researchers (such as faculty, staff, and PhD students) in [supported
countries](/gemini-api/docs/available-regions) can apply to receive Gemini API
credits and higher rate limits for research projects. This support enables
higher throughput for scientific experiments and advances research.

We are particularly interested in the research areas in the following section,
but we welcome applications from diverse scientific disciplines:

* **Evaluations and benchmarks**: Community-endorsed evaluation methods that
  can provide a strong performance signal in areas such as factuality, safety,
  instruction following, reasoning, and planning.
* **Accelerating scientific discovery to benefit humanity**: Potential
  applications of AI in interdisciplinary scientific research, including areas
  such as rare and neglected diseases, experimental biology, materials science,
  and sustainability.
* **Embodiment and interactions**: Utilizing large language models to
  investigate novel interactions within the fields of embodied AI, ambient
  interactions, robotics, and human-computer interaction.
* **Emergent capabilities**: Exploring new agentic capabilities required to
  enhance reasoning and planning, and how capabilities can be expanded during
  inference (e.g., by utilizing Gemini Flash).
* **Multimodal interaction and understanding**: Identifying gaps and
  opportunities for multimodal foundational models for analysis, reasoning,
  and planning across a variety of tasks.

Eligibility: Only individuals (faculty members, researchers or equivalent)
affiliated with a valid academic institution, or academic research organization
can apply. Note that API access and credits will be granted and removed
at Google's discretion. We review applications on a monthly basis.

### Start researching with the Gemini API

[Apply now](https://forms.gle/HMviQstU8PxC5iCt5)

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-04-01 UTC.

[[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Missing the information I need","missingTheInformationINeed","thumb-down"],["Too complicated / too many steps","tooComplicatedTooManySteps","thumb-down"],["Out of date","outOfDate","thumb-down"],["Samples / code issue","samplesCodeIssue","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-04-01 UTC."],[],[]]